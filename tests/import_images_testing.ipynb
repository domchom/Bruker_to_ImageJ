{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d133784",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Files processed::   0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Files processed::   6%|▌         | 1/17 [00:00<00:13,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 200DCE_DC191_c-001!\n",
      "************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Files processed::  12%|█▏        | 2/17 [00:01<00:09,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 200DCE_DC191_c-002!\n",
      "************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Files processed::  18%|█▊        | 3/17 [00:01<00:08,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 200DCE_DC191_c-004!\n",
      "************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Files processed::  24%|██▎       | 4/17 [00:02<00:10,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 200DCE_DC191_c-005!\n",
      "************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Files processed::  29%|██▉       | 5/17 [00:04<00:14,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 200DCE_DC191_c-007!\n",
      "************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Files processed::  35%|███▌      | 6/17 [00:06<00:13,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 200DCE_DC191_c-008!\n",
      "************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Files processed::  41%|████      | 7/17 [00:07<00:12,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 200DCE_p78_c-001!\n",
      "************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Files processed::  47%|████▋     | 8/17 [00:09<00:12,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 200DCE_p78_c-002!\n",
      "************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Files processed::  53%|█████▎    | 9/17 [00:09<00:08,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 200DCE_p78_c-004!\n",
      "************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Files processed::  59%|█████▉    | 10/17 [00:10<00:06,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 200DCE_p78_c-005!\n",
      "************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Files processed::  65%|██████▍   | 11/17 [00:11<00:05,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 200DCE_p78_c-006!\n",
      "************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Files processed::  71%|███████   | 12/17 [00:11<00:04,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 200DCE_p78_c-007!\n",
      "************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Files processed::  76%|███████▋  | 13/17 [00:12<00:02,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 200DCE_p78_c-009!\n",
      "************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Files processed::  82%|████████▏ | 14/17 [00:13<00:02,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 200DCE_p78_c-010!\n",
      "************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Files processed::  88%|████████▊ | 15/17 [00:14<00:01,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 200DCE_p78_c-011!\n",
      "************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Files processed:: 100%|██████████| 17/17 [00:15<00:00,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 200DCE_p78_c-013!\n",
      "************************************************************\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import timeit\n",
    "import tifffile\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# TODO: make a log file of all the files that were processed and any that failed\n",
    "\n",
    "parent_folder_path = '/Volumes/T7/200DCE_240228_3xGFP-Ect2PH(PBC)_SFC/scope_folders'\n",
    "\n",
    "def get_pixel_size(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    microns_per_pixel_element = root.find(\".//PVStateValue[@key='micronsPerPixel']\")\n",
    "    microns_per_pixel = {}\n",
    "\n",
    "    for indexed_value in microns_per_pixel_element.findall(\"./IndexedValue\"):\n",
    "        axis = indexed_value.attrib[\"index\"]\n",
    "        value = float(indexed_value.attrib[\"value\"])\n",
    "        microns_per_pixel[axis] = value \n",
    "\n",
    "    return microns_per_pixel['XAxis'], microns_per_pixel['YAxis']\n",
    "\n",
    "def get_frame_rate(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    frames = root.findall('.//Frame')\n",
    "    absolute_times = {}\n",
    "\n",
    "    for index, frame in enumerate(frames, start=1):\n",
    "        absolute_time = frame.attrib.get('absoluteTime')\n",
    "        files = frame.findall('File')\n",
    "        for file in files:\n",
    "            filename = file.attrib.get('filename')\n",
    "            if \"000001.ome.tif\" in filename:\n",
    "                name = int(filename.split(\"_\")[-3].split(\"e\")[-1])\n",
    "                absolute_times[name] = absolute_time\n",
    "\n",
    "    num_frames = len(absolute_times)\n",
    "        \n",
    "    total_time = float(absolute_times[num_frames])\n",
    "    framerate = total_time / num_frames\n",
    "\n",
    "    return framerate\n",
    "\n",
    "def make_log(\n",
    "    directory: str, \n",
    "    logParams: dict\n",
    "):\n",
    "    '''\n",
    "    Convert dictionary of parameters to a log file and save it in the directory\n",
    "    '''\n",
    "    logPath = os.path.join(directory, f\"!image_conversion_log.txt\")\n",
    "    logFile = open(logPath, \"w\")                                    \n",
    "    logFile.write(\"\\n\" + now.strftime(\"%Y-%m-%d %H:%M\") + \"\\n\")     \n",
    "    for key, value in logParams.items():                            \n",
    "        logFile.write('%s: %s\\n' % (key, value))                    \n",
    "    logFile.close()   \n",
    "\n",
    "def create_hyperstack(folder_path):\n",
    "    # convert and save the tiff stack\n",
    "    all_files = []\n",
    "    mip_folder_path = os.path.join(folder_path, \"MIP\")\n",
    "    if os.path.exists(mip_folder_path) and os.path.isdir(mip_folder_path):\n",
    "        files_in_mip = [os.path.join(mip_folder_path, file) for file in os.listdir(mip_folder_path)]\n",
    "        all_files.extend(files_in_mip)\n",
    "\n",
    "    channel_files = {}\n",
    "    for file in all_files:\n",
    "        channel_name = os.path.basename(file).split('_')[-2] \n",
    "        if channel_name not in channel_files:\n",
    "            channel_files[channel_name] = []\n",
    "        channel_files[channel_name].append(file)\n",
    "\n",
    "    # Read images for each channel\n",
    "    channel_images = {}\n",
    "    for channel_name, files in channel_files.items():\n",
    "        channel_images[channel_name] = [tifffile.imread(file) for file in files]\n",
    "\n",
    "    # Stack images for each channel\n",
    "    stacked_images = {}\n",
    "    for channel_name, images in channel_images.items():\n",
    "        stacked_images[channel_name] = np.stack(images)\n",
    "\n",
    "    # Stack images across channels\n",
    "    merged_images = np.stack(list(stacked_images.values()), axis=1)\n",
    "\n",
    "    return merged_images\n",
    "\n",
    "# performance tracker\n",
    "start = timeit.default_timer()\n",
    "\n",
    "# get the folders\n",
    "folders = [folder for folder in os.listdir(parent_folder_path) if os.path.isdir(os.path.join(parent_folder_path, folder))]\n",
    "folders = sorted(folders)\n",
    "\n",
    "# create the output folder\n",
    "output_path = os.path.join(parent_folder_path, \"!processed_images\")\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# log file\n",
    "log_params = {'Files Not Processed': [],\n",
    "              'Files Processed': []}\n",
    "\n",
    "with tqdm(total = len(folders)) as pbar:\n",
    "    pbar.set_description('Files processed:')\n",
    "    for folder in folders:\n",
    "        print('******'*10)\n",
    "        try:\n",
    "            folder_path = os.path.join(parent_folder_path, folder)\n",
    "            \n",
    "            # set the image name\n",
    "            image_name = os.path.join(output_path, f\"MAX_{folder}_raw.tif\")\n",
    "\n",
    "            if os.path.exists(image_name):\n",
    "                print(f\"{folder} already exists!\")\n",
    "                log_params['Files Not Processed'].append(f'{folder}: Already exists!')\n",
    "                pass\n",
    "            else:\n",
    "                # get the xml file\n",
    "                xml_file = [file for file in os.listdir(folder_path) if os.path.splitext(file)[1] == \".xml\"]\n",
    "                xml_file = os.path.join(folder_path, xml_file[0])\n",
    "\n",
    "                # get the pixel size\n",
    "                X_microns_per_pixel, Y_microns_per_pixel =  get_pixel_size(xml_file)\n",
    "\n",
    "                # get the frame rate\n",
    "                framerate = get_frame_rate(xml_file)\n",
    "\n",
    "                # create the hyperstack\n",
    "                hyperstack = create_hyperstack(folder_path)\n",
    "                \n",
    "                # save the hyperstack\n",
    "                \n",
    "                tifffile.imsave(\n",
    "                    image_name, \n",
    "                    hyperstack,\n",
    "                    imagej=True,\n",
    "                    resolution=(1/X_microns_per_pixel, 1/Y_microns_per_pixel),\n",
    "                    metadata={'axes': 'TCYX',\n",
    "                            'finterval': framerate,\n",
    "                            'mode': 'composite'}\n",
    "                    )\n",
    "\n",
    "                log_params['Files Processed'].append(folder)\n",
    "                print(f\"Successfully processed {folder}!\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            log_params['Files Not Processed'].append(f'{folder}: {e}')\n",
    "            pass\n",
    "\n",
    "        pbar.update(1)\n",
    "    \n",
    "end = timeit.default_timer()\n",
    "log_params[\"Time Elapsed\"] = f\"{end - start:.2f} seconds\"\n",
    "\n",
    "make_log(parent_folder_path, log_params)\n",
    "\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a36189",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tifffile\n",
    "\n",
    "parent_folder_path = '/Volumes/T7/201DCE_240229_3xGFP-Ect2PH(PBC)_tagged-Ect2_SFC'\n",
    "\n",
    "# Find all folders within the parent folder\n",
    "folders = [folder for folder in os.listdir(parent_folder_path) if os.path.isdir(os.path.join(parent_folder_path, folder))]\n",
    "\n",
    "# Get all files in each folder\n",
    "for folder in folders:\n",
    "    try:\n",
    "        all_files = []\n",
    "        folder_path = os.path.join(parent_folder_path, folder)\n",
    "        mip_folder_path = os.path.join(folder_path, \"MIP\")\n",
    "        if os.path.exists(mip_folder_path) and os.path.isdir(mip_folder_path):\n",
    "            files_in_mip = [os.path.join(mip_folder_path, file) for file in os.listdir(mip_folder_path)]\n",
    "            all_files.extend(files_in_mip)\n",
    "\n",
    "        ch1_files = [file for file in all_files if \"Ch1\" in file]\n",
    "        ch2_files = [file for file in all_files if \"Ch2\" in file]\n",
    "\n",
    "        ch1_image = []\n",
    "        for file in ch1_files:\n",
    "            image = tifffile.imread(file)\n",
    "            ch1_image.append(image)\n",
    "\n",
    "        ch2_image = []\n",
    "        for file in ch2_files:\n",
    "            image = tifffile.imread(file)\n",
    "            ch2_image.append(image)\n",
    "\n",
    "        # Convert the list to a numpy array\n",
    "        ch1_image = np.stack(ch1_image)\n",
    "        ch2_image = np.stack(ch2_image)\n",
    "        \n",
    "        output_path = os.path.join(parent_folder_path, \"!processed_images\")\n",
    "        if not os.path.exists(output_path):\n",
    "            os.makedirs(output_path)\n",
    "\n",
    "        merged_image = np.stack([ch1_image, ch2_image], axis=1)\n",
    "\n",
    "        # Save the multi-frame image\n",
    "        tifffile.imsave(os.path.join(output_path, f\"MAX_{folder}_raw.tif\"), merged_image)\n",
    "\n",
    "        print(f\"Successfully processed {folder}!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process {folder}!\")\n",
    "        print(e)\n",
    "        pass\n",
    "    \n",
    "print(\"Done!\")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7f3d8503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'XAxis': 0.26614481409002, 'YAxis': 0.26614481409002, 'ZAxis': 1.0}\n",
      "{'XAxis': 0.26614481409002, 'YAxis': 0.26614481409002, 'ZAxis': 1.0}\n",
      "{'XAxis': 0.26614481409002, 'YAxis': 0.26614481409002, 'ZAxis': 1.0}\n",
      "{'XAxis': 0.26614481409002, 'YAxis': 0.26614481409002, 'ZAxis': 1.0}\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/path/to/save/csv/file.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 74\u001b[0m\n\u001b[1;32m     71\u001b[0m     data\u001b[38;5;241m.\u001b[39mappend([folder, pixel_size, frame_rate])\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# Write the data to the CSV file\u001b[39;00m\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcsv_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m     75\u001b[0m     writer \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mwriter(file)\n\u001b[1;32m     76\u001b[0m     writer\u001b[38;5;241m.\u001b[39mwriterow(header)\n",
      "File \u001b[0;32m~/anaconda3/envs/wave_anal/lib/python3.11/site-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/path/to/save/csv/file.csv'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "\n",
    "parent_folder_path = '/Users/domchom/random_movies/anilyzer_test_data/SFC_t-series'\n",
    "\n",
    "# Find all folders within the parent folder\n",
    "folders = [folder for folder in os.listdir(parent_folder_path) if os.path.isdir(os.path.join(parent_folder_path, folder))]\n",
    "\n",
    "# Get all files in each folder\n",
    "for folder in folders:\n",
    "    all_files = []\n",
    "    folder_path = os.path.join(parent_folder_path, folder)\n",
    "    \n",
    "    xml_file = [file for file in os.listdir(folder_path) if file.endswith(\".xml\")]\n",
    "    xml_file = os.path.join(folder_path, xml_file[0])\n",
    "\n",
    "    # Parse the XML file\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    microns_per_pixel_element = root.find(\".//PVStateValue[@key='micronsPerPixel']\")\n",
    "\n",
    "    # Extract microns per pixel values\n",
    "    microns_per_pixel = {}\n",
    "    for indexed_value in microns_per_pixel_element.findall(\"./IndexedValue\"):\n",
    "        axis = indexed_value.attrib[\"index\"]\n",
    "        value = float(indexed_value.attrib[\"value\"])\n",
    "        microns_per_pixel[axis] = value \n",
    "\n",
    "    print(microns_per_pixel)\n",
    "\n",
    "    # Find all Frame elements\n",
    "    frames = root.findall('.//Frame')\n",
    "\n",
    "    absolute_times = {}\n",
    "\n",
    "    # Extract and print the absolute time attribute value for each Frame\n",
    "    for frame in frames:\n",
    "        absolute_time = frame.attrib.get('absoluteTime')\n",
    "        files = frame.findall('File')\n",
    "        for file in files:\n",
    "            filename = file.attrib.get('filename')\n",
    "            if \"000005.ome.tif\" in filename:\n",
    "                name = filename.split(\"_\")[-3]\n",
    "                name = name.split(\"e\")[-1]\n",
    "                name = int(name)\n",
    "                absolute_times[name] = absolute_time\n",
    "\n",
    "    num_frames = len(absolute_times)\n",
    "    total_time = float(absolute_times[num_frames])\n",
    "    \n",
    "    framerate = total_time / num_frames\n",
    "\n",
    "# Define the CSV file path\n",
    "csv_file_path = '/path/to/save/csv/file.csv'\n",
    "\n",
    "# Define the header of the CSV file\n",
    "header = ['Folder Name', 'Pixel Size', 'Frame Rate']\n",
    "\n",
    "# Create a list to store the data for each folder\n",
    "data = []\n",
    "\n",
    "# Iterate over the folders\n",
    "for folder in folders:\n",
    "    # Get the pixel size and frame rate for the folder\n",
    "    pixel_size = microns_per_pixel['ZAxis']\n",
    "    frame_rate = framerate\n",
    "    \n",
    "    # Append the folder name, pixel size, and frame rate to the data list\n",
    "    data.append([folder, pixel_size, frame_rate])\n",
    "\n",
    "# Write the data to the CSV file\n",
    "with open(csv_file_path, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header)\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(\"CSV file saved successfully!\")\n",
    "    \n",
    "            \n",
    "    \n",
    "    \n",
    "print(\"Done!\")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9942dee5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "9e7c5e355466f7aa2375f2a09663ffde6f6d12fe8bf8f1a4007efb595e6d1812"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
